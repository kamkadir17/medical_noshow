{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import calendar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "fmt = lambda x,pos: '{:.0%}'.format(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./KaggleV2-May-2016.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below 5 questions is what we are going to try and answer for \n",
    "# - can we identify any trends in who misses the appointment\n",
    "\n",
    "# Insights derived\n",
    "# 1. Which Gender predominatly missed the appointment? Is there any trend ? \n",
    "# 2. Is there day of the week having any impact on No-show ? \n",
    "# 3. Does the SMS reminder help reduce the No-show occurrence ?\n",
    "# 4. Which Age group needs more appointments and what are they success rate in meeting the appointment ?\n",
    "# 5. Gap between scheduled day and appointment day ?\n",
    "\n",
    "# If you are further interested on this dataset, you could also potentially look at answering the following questions.\n",
    "# 1. Does medication conditions have any trend over No-show ?\n",
    "# 2. Does scholarship have an impact on No-show ?\n",
    "# 3. Which Neighborhoods have more No-show ?\n",
    "# 4. Timeseries trend over Appointment days for No-show vs show ?\n",
    "# 5. Is there any trend in how soon the appointments are made for these age groups ?\n",
    "\n",
    "# I have created 3 classification models and used them for predicting if an appointment could be a show or No-show?\n",
    "# 1. Can we predict No-Show / Show based on the data\n",
    "# 1.1 Logistic Regression\n",
    "# 1.2 Random Forest\n",
    "# 1.3 Naive Bayes Classification\n",
    "# 2. Using techniques to rebalance imbalanced outputs so precision can be improved\n",
    "# 2.1 Undersampling\n",
    "# 2.2 Oversampling\n",
    "# 2.3 Synthetic Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now infer the basic information of the dataframe and see what columns might be useful\n",
    "df.info()\n",
    "\n",
    "# based on the data - Initial findings / questions that come up are as follows\n",
    "# There seems to be no NaN data. This total rows in the dataset is 110,527 and all columns have the same number of values.\n",
    "# We do have two dates - One the day when the appointment was scheduled and the day when the actual appointment was.\n",
    "# Probably we can derive some additional features from these dates to see how far back the appointment was made? Does it have any weight on missing the appointment ?\n",
    "# We also have few categorical values - which we might need to do One-Hot encoding so that we have each unique value in the category represented in a binary format. Also we need only N-1 unique values to be represented in One-Hot encoding so we will be removing the excess dummy value.\n",
    "# We do have Age. We can classify the Age into multiple groups to understand which Age group honors more the appointment and which doesn't. Like if the appointment is for kids, do they make it or if it was for senior people do they make it ?\n",
    "\n",
    "# Lets start exploring and try and find answers to these intriguing questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight 1: Analyze if Gender has an Impact on No-show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 1.1\n",
    "# A simple crosstab of Gender vs No-show \n",
    "\n",
    "pd.crosstab(df.Gender, df['No-show'], margins=True, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 1.2\n",
    "# Crosstab between Gender vs No-show normalized to percentages to identify its impact. \n",
    "# We then use Seaborn heatmap to visually see the output.\n",
    "\n",
    "\n",
    "ax = sns.heatmap(pd.crosstab(df.Gender, df['No-show'], normalize='index'),\n",
    "            cmap=\"YlGnBu\", annot=True,  cbar=True, fmt='.0%',\n",
    "            cbar_kws={'format': FuncFormatter(fmt)});\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_title(\"Gender vs Medical No Show\")\n",
    "ax.set_ylim(bottom + 0.1, top - 0.1);\n",
    "ax.get_figure().savefig('./gender_noshow.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 1.3\n",
    "# Crosstab between Gender vs No-show normalized to percentages to identify its impact. \n",
    "# We then use Seaborn heatmap to visually see the output.\n",
    "\n",
    "ax = sns.heatmap(pd.crosstab(df.Gender, df['No-show'], normalize='columns'),\n",
    "            cmap=\"YlGnBu\", annot=True,  cbar=False, fmt='.0%',\n",
    "            cbar_kws={'format': FuncFormatter(fmt)});\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_title(\"Gender vs Medical No Show\")\n",
    "ax.set_ylim(bottom + 0.1, top - 0.1);\n",
    "ax.get_figure().savefig('./gender_appoints_booked.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference 1:\n",
    "\n",
    "1. Gender doesnt seem to play a major role in missing the appointment. (Analysis 1.2)\n",
    "2. Both Male and Female appointees missed by 20% of the time. (Analysis 1.2)\n",
    "3. Females took 30% more appointments than Male. (Analysis 1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight 2: Is there any interesting trends or patterns for Appointments with respect to the 'Days of the week' ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do this analysis, we need to first get the weekday of the appointment. We can do this by writing a helper lamba function\n",
    "\n",
    "#1. Create two new columns for populating the weekday_number and 'day of the week' of the appointment day. \n",
    "# Its a numeric value - 0 to 6 representing Monday to Sunday.\n",
    "\n",
    "wd_num = lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").date().weekday()\n",
    "wd = lambda x: calendar.day_name[x]\n",
    "df['weekday_num'] = df['AppointmentDay'].apply(wd_num)\n",
    "df['weekday'] = df['weekday_num'].apply(wd)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 2.1\n",
    "#Crosstab between weekday and total appointments and No-show details\n",
    "\n",
    "pd.crosstab([df.weekday_num, df.weekday], df['No-show'],rownames=[\"Weekday#\",\"Day of the Week\"], colnames=[\"No Show\"], margins=True, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 2.2\n",
    "# Crosstab between Weekday vs No-show normalized to percentages to identify its impact. \n",
    "# We then use Seaborn heatmap to visually see the output.\n",
    "\n",
    "ax = sns.heatmap(pd.crosstab([df.weekday_num, df.weekday], df['No-show'],rownames=[\"Weekday#\",\"Day of the Week\"], colnames=[\"No Show\"], normalize='index'),\n",
    "            cmap=\"YlGnBu\", annot=True,  cbar=True, fmt='.0%',\n",
    "            cbar_kws={'format': FuncFormatter(fmt)});\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_title(\"Weekday vs Medical No Show\")\n",
    "ax.set_ylim(bottom + 0.1, top - 0.1);\n",
    "ax.get_figure().savefig('./weekday_noshow.png',pad_inches=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference 2:\n",
    "\n",
    "1. The Medical clinic seems to work only from Monday to Friday with probably emergency cases seen on Saturday. Hence the Saturday count is way too less. Sunday is a holiday. (Analysis 2.1)\n",
    "2. Tuesday and Wednesday seems to be the busy days for the clinic followed by Monday, Friday & Thursday respectively.(Analysis 2.1)\n",
    "3. The day of the week doesn't have any impact on the No-Show of the appointments. (Analysis 2.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight 3: Did the SMS Reminders help reduce the No-Show for the patients or any groups in particular ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 3.1\n",
    "# Crosstab between SMS vs No-show normalized to percentages to identify its impact. \n",
    "\n",
    "# Lets find out how many number of days before they booked the appointment. \n",
    "# And lets see if there is any trend in these bookings being missed / SMS helping not to miss the appointments\n",
    "\n",
    "df['SMS_Desc'] = df['SMS_received'].apply(lambda x: 'Sent' if x == 1 \\\n",
    "                                                                   else 'Not Sent')\n",
    "\n",
    "ax = sns.heatmap(pd.crosstab([df.SMS_Desc], df['No-show'],rownames=[\"SMS Reminder\"], colnames=[\"No Show\"],  normalize='index'),\n",
    "            cmap=\"YlGnBu\", annot=True,  cbar=True, fmt='.0%',\n",
    "            cbar_kws={'format': FuncFormatter(fmt)});\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_title(\"SMS Received vs Medical No Show\")\n",
    "ax.set_ylim(bottom + 0.1, top - 0.1);\n",
    "ax.get_figure().savefig('./sms_received_noshow.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference 3:\n",
    "1. We do find an interesting observation that SMS Reminders have actually NOT helped in reducing the No-Show but rather increased its occurrence.\n",
    "2. When compared, there are 28% of No-Show SMS received patients to 17% of No-Show who never received any reminder of their appointments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight 4: Does Booking in Advance or Age group has any trend with missing the appointments ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we do this, lets add a couple of new features that might come in handy\n",
    "\n",
    "#1. Lets also group the patients based on Age into 6 broad categories and see if any of these groups had any impact\n",
    "#   Baby               -> 0 - 3\n",
    "#   Kid                -> 4  - 12\n",
    "#   Adolescent         -> 13 - 19\n",
    "#   Young_Adult        -> 20 - 39\n",
    "#   Adult              -> 40 - 64\n",
    "#   Senior             -> 65 & Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do a quick summary of value counts for each Age. We see that there is 1 record with Age = -1. \n",
    "# We will consider this age row also as a Baby for our analysis.\n",
    "df.Age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_age_groups(Age):\n",
    "    \"\"\"\n",
    "    This function creates a new feature to the input dataframe based on the Age.\n",
    "    \n",
    "    It creates categorical values based on Age. It categorizes the Age into 1 of the 6 categories.\n",
    "    #   Baby               -> 0 - 3\n",
    "    #   Kid                -> 4  - 12\n",
    "    #   Adolescent         -> 13 - 19\n",
    "    #   Young_Adult        -> 20 - 39\n",
    "    #   Adult              -> 40 - 64\n",
    "    #   Senior             -> 65 & Above\n",
    "    \n",
    "    INPUT:\n",
    "    col - Age column\n",
    "    \n",
    "    OUTPUT:\n",
    "    Age_Group\n",
    "    \n",
    "    \"\"\"\n",
    "    if Age >= 65:\n",
    "        Age_Group = 'Senior'\n",
    "    elif Age >= 40:\n",
    "        Age_Group = 'Adult'\n",
    "    elif Age >= 20:\n",
    "        Age_Group = 'Young_Adult'\n",
    "    elif Age >= 13:\n",
    "        Age_Group = 'Adolescent'\n",
    "    elif Age >= 4:\n",
    "        Age_Group = 'Kid'   \n",
    "    else:\n",
    "        Age_Group = 'Baby'         \n",
    "    \n",
    "    return Age_Group\n",
    "\n",
    "df['Age_Group'] = df['Age'].apply(create_age_groups)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 4.1\n",
    "# Crosstab between Age_Group vs No-show normalized to percentages to identify its impact. \n",
    "# We then use Seaborn heatmap to visually see the output.\n",
    "\n",
    "ax = sns.heatmap(pd.crosstab([df.Age_Group], df['No-show'],rownames=[\"Age Group\"], colnames=[\"No Show\"], normalize='index'),\n",
    "            cmap=\"YlGnBu\", annot=True,  cbar=True, fmt='.0%',\n",
    "            cbar_kws={'format': FuncFormatter(fmt)});\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_title(\"Age Group vs Medical No Show %\")\n",
    "ax.set_ylim(bottom + 0.1, top - 0.1);\n",
    "ax.get_figure().savefig('./age_group_noshow_percent.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 4.2\n",
    "# Crosstab between Age_Group vs No-show normalized to percentages to identify its impact. \n",
    "# We then use Seaborn heatmap to visually see the output.\n",
    "\n",
    "ax = sns.heatmap(pd.crosstab([df.Age_Group], df['No-show'],rownames=[\"Age Group\"], colnames=[\"No Show\"]),\n",
    "            cmap=\"YlGnBu\", annot=True,  cbar=True, fmt='4.0f');\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_title(\"Age Group vs Medical No Show\")\n",
    "ax.set_ylim(bottom + 0.1, top - 0.1);\n",
    "ax.get_figure().savefig('./age_group_noshow.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Lets create a new feature for number of days in advance a booking was made. If it is zero, it is same day appointment\n",
    "\n",
    "dt = lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").date()  #\"%Y-%m-%dT%H:%M:%SZ\"\n",
    "df['AdvanceDays'] = (df['AppointmentDay'].apply(dt) - df['ScheduledDay'].apply(dt)).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we deep dive into AdvanceDays booking, lets see how that correlates to No-Show. \n",
    "fig, ax = plt.subplots(1, 2,figsize=(8,4))\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.75, hspace=None)\n",
    "# The parameter meanings (and suggested defaults) are:\n",
    "\n",
    "# left  = 0.125  # the left side of the subplots of the figure\n",
    "# right = 0.9    # the right side of the subplots of the figure\n",
    "# bottom = 0.1   # the bottom of the subplots of the figure\n",
    "# top = 0.9      # the top of the subplots of the figure\n",
    "# wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
    "# hspace = 0.2   # the amount of height reserved for white space between subplots\n",
    "\n",
    "ax = ax.ravel()\n",
    "ax[0].hist(df[df['No-show']=='No']['AdvanceDays'], bins=75)\n",
    "ax[1].hist(df[df['No-show']=='Yes']['AdvanceDays'], bins=75);\n",
    "#bottom, top = ax.get_ylim()\n",
    "ax[0].set_title(\"Histogram - Honor Appointments\")\n",
    "ax[1].set_title(\"Histogram - Medical No Show\");\n",
    "\n",
    "# We see that the number of appointments booked for various advance booking are not same. \n",
    "# Also the No-show fluctuates across these days. \n",
    "# Hence lets create custom bins for the booking days and then see if we are able to see any pattern\n",
    "plt.savefig('./adv_booking_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Create advance_days_bin for grouping the booked in advance days into logical buckets\n",
    "def create_advance_days_bins(advance_days):\n",
    "    \"\"\"\n",
    "        This function creates a new feature to the input dataframe based on the AdvanceDays.\n",
    "\n",
    "        It creates categorical values based on AdvanceDays. It categorizes the Age into 1 of the 10 categories.\n",
    "        #   90-Days+               -> More than or equal to 90 days in advance\n",
    "        #   30-Days+               -> More than or equal to 30 days in advance\n",
    "        #   7-Days+                -> More than or equal to 7 days in advance\n",
    "        #   6-Days                 -> 6 days in advance\n",
    "        #   5-Days                 -> 5 days in advance\n",
    "        #   4-Days                 -> 4 days in advance\n",
    "        #   3-Days                 -> 3 days in advance\n",
    "        #   2-Days                 -> 2 days in advance\n",
    "        #   1-Days                 -> 1 days in advance\n",
    "        #   0-Days                 -> Same day\n",
    "\n",
    "        INPUT:\n",
    "        advance_days - Number of days in advance an appointment is booked\n",
    "\n",
    "        OUTPUT:\n",
    "        adv_bin - AdvanceDays Bin\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if advance_days >= 90:\n",
    "        adv_bin = '90-Days+'\n",
    "    elif advance_days >= 30:\n",
    "        adv_bin = '30-Days+'             \n",
    "    elif advance_days >= 7:\n",
    "        adv_bin = '07-Days+'\n",
    "    elif advance_days == 6:\n",
    "        adv_bin = '06-Days'\n",
    "    elif advance_days == 5:\n",
    "        adv_bin = '05-Days'\n",
    "    elif advance_days == 4:\n",
    "        adv_bin = '04-Days'\n",
    "    elif advance_days == 3:\n",
    "        adv_bin = '03-Days'\n",
    "    elif advance_days == 2:\n",
    "        adv_bin = '02-Days'\n",
    "    elif advance_days == 1:\n",
    "        adv_bin = '01-Day'\n",
    "    else:\n",
    "        adv_bin = '00-SameDay'        \n",
    "    return adv_bin\n",
    "\n",
    "df['adv_bin'] = df['AdvanceDays'].apply(create_advance_days_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 4.3\n",
    "# Crosstab between AdvanceBin vs No-show normalized to percentages to identify its impact. \n",
    "# We then use Seaborn heatmap to visually see the output.\n",
    "\n",
    "ax = sns.heatmap(pd.crosstab([df.adv_bin], df['No-show'],rownames=[\"Advance Booking\"], colnames=[\"No Show\"]),\n",
    "            cmap=\"YlGnBu\", annot=True,  cbar=True, fmt='4.0f');\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_title(\"Advance Booking vs Medical No Show\")\n",
    "ax.set_ylim(bottom + 0.1, top - 0.1);\n",
    "ax.get_figure().savefig('./advance_bookins_noshow.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference 4:\n",
    "1. Adolescents missed their appointments by 26% followed by Kids (23%) and Young Adults (23%). These are the top 3 No-show based on percentages (Analysis 4.1)\n",
    "2. In terms of pure absolute number of appointments missed, Young Adults & Adults take the spot with 6600+ No-shows each (Analysis 4.2)\n",
    "3. Majority of the patients for the clinic were Adults (30K) followed by Young Adults (22K) and then the Seniors (12K) (Analysis 4.2)\n",
    "4. In terms of missed appointments, the same day appointments were the least interms of misses (~4%). Whereas the highest appointment misses happen when the booking was made more than 7 days. About 14K missed in 44K. Roughly 31.5%. (Analysis 4.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction\n",
    "#### Can we predict if a new patient will Show or No-Show ?\n",
    "For this question, we will do the following by doing the following\n",
    "\n",
    "1. Identify all unnecessary columns in the Dataframe that are not required or add any value to the findings. Remove them.\n",
    "2. Identify all categorical columns and convert them using One-Hot encoding with dropFirst = True\n",
    "3. Separate the Dataframe into X input and y output series.\n",
    "4. Split into train and test\n",
    "5. Apply model on train dataset\n",
    "6. Test model using test dataset\n",
    "7. Measure the score of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_predict(model, X_train, y_train, X_test, y_test, target_names, model_name):\n",
    "    #5. Apply model on train dataset\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #6. Test model using test dataset\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    #7. Measure the score of accuracy\n",
    "    print('{1} Evaluation...Accuracy Score = {0:3.2f}'.format(accuracy_score(y_test, y_pred), model_name))\n",
    "\n",
    "    #8. Confusion Matrix of the prediction\n",
    "    print(confusion_matrix(y_test, y_pred ))\n",
    "\n",
    "    #9. Classification Report of the prediction\n",
    "    print(classification_report(y_test, y_pred,target_names=target_names))    \n",
    "    return y_pred\n",
    "\n",
    "def logistic_regression(X_train, y_train, X_test, y_test, target_names, model_name):\n",
    "    # Logistics Regression Model\n",
    "    reg_lr = LogisticRegression(random_state = 0)    \n",
    "    y_pred_lr = model_fit_predict(reg_lr, X_train, y_train, X_test, y_test, target_names, model_name)\n",
    "    return y_pred_lr\n",
    "\n",
    "def random_forest_classifier(X_train, y_train, X_test, y_test, target_names, model_name):\n",
    "    # Random Forest Classification Model\n",
    "    clf_rfc = RandomForestClassifier(random_state = 0, n_estimators=10)\n",
    "    y_pred_rfc = model_fit_predict(clf_rfc, X_train, y_train, X_test, y_test, target_names, model_name)\n",
    "    return y_pred_rfc\n",
    "\n",
    "def naive_bayes_classifier(X_train, y_train, X_test, y_test, target_names, model_name):\n",
    "    # Naive Bayes Gaussian Model\n",
    "    #5. Apply model on train dataset\n",
    "    clf_nb = GaussianNB()\n",
    "    y_pred_nb = model_fit_predict(clf_nb, X_train, y_train, X_test, y_test, target_names, model_name)\n",
    "    return y_pred_nb\n",
    "\n",
    "def run_all_models(X_train, y_train, X_test, y_test, target_names):\n",
    "    #5. Model Creation and Validation\n",
    "    y_pred_lr  = logistic_regression(X_train, y_train, X_test, y_test, target_names, 'Logistic Regression')\n",
    "    y_pred_rfc = random_forest_classifier(X_train, y_train, X_test, y_test, target_names,'Random Forest')\n",
    "    y_pred_nb  = naive_bayes_classifier(X_train, y_train, X_test, y_test, target_names,'Naive Bayes')\n",
    "    \n",
    "# Lets create the Model\n",
    "#df = df_bkup\n",
    "#df_bkup = df\n",
    "#1. Identify all unnecessary columns in the Dataframe that are not required or add any value to the findings. Remove them.\n",
    "df = df.drop(columns=['PatientId','AppointmentID','ScheduledDay','AppointmentDay','Age','weekday','SMS_Desc','AdvanceDays'])\n",
    "\n",
    "#2. Identify all categorical columns and convert them using One-Hot encoding with dropFirst = True\n",
    "df = pd.get_dummies(df, columns = ['Gender','Neighbourhood','Age_Group','adv_bin','No-show'], drop_first=True)\n",
    "\n",
    "#3. Separate the Dataframe into X input and y output series.\n",
    "X = df.drop(['No-show_Yes'], axis=1)\n",
    "y = df['No-show_Yes']\n",
    "target_names = ['Show', 'No-Show']\n",
    "\n",
    "#4. Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.3)\n",
    "\n",
    "#5. Model Execution\n",
    "run_all_models(X_train, y_train, X_test, y_test, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Resample - Undersampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.3)\n",
    "\n",
    "df_train = pd.concat((X_train, pd.DataFrame(y_train.T)),axis=1)\n",
    "undersample_size = y_train.value_counts().min()\n",
    "# Display new class counts\n",
    "print (y_train.value_counts())\n",
    "\n",
    "df_train_major = df_train[df_train['No-show_Yes']==0]\n",
    "df_train_minor = df_train[df_train['No-show_Yes']==1]\n",
    "\n",
    "df_train_major_undersample = resample(df_train_major, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=undersample_size,    \n",
    "                                 random_state=0) \n",
    "df_train = pd.concat([df_train_major_undersample, df_train_minor], axis = 0)\n",
    "X_train = df_train.drop(columns = ['No-show_Yes'])\n",
    "y_train = df_train['No-show_Yes']\n",
    " \n",
    "# Display new class counts\n",
    "print (y_train.value_counts())\n",
    "\n",
    "#5. Model Execution\n",
    "run_all_models(X_train, y_train, X_test, y_test, target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Resample - Oversampling\n",
    "from sklearn.utils import resample\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.3)\n",
    "\n",
    "df_train = pd.concat((X_train, pd.DataFrame(y_train.T)),axis=1)\n",
    "oversample_size = y_train.value_counts().max()\n",
    "# Display new class counts\n",
    "print (y_train.value_counts())\n",
    "\n",
    "df_train_major = df_train[df_train['No-show_Yes']==0]\n",
    "df_train_minor = df_train[df_train['No-show_Yes']==1]\n",
    "\n",
    "df_train_minor_oversample = resample(df_train_minor, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=oversample_size,    \n",
    "                                 random_state=0) \n",
    "df_train = pd.concat([df_train_major, df_train_minor_oversample], axis = 0)\n",
    "X_train = df_train.drop(columns = ['No-show_Yes'])\n",
    "y_train = df_train['No-show_Yes']\n",
    " \n",
    "# Display new class counts\n",
    "print (y_train.value_counts())\n",
    "\n",
    "#5. Model Execution\n",
    "run_all_models(X_train, y_train, X_test, y_test, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Resample - Synthetic sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.3)\n",
    "\n",
    "#SMOTE\n",
    "import sys\n",
    "!{sys.executable} -m pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=12)\n",
    "# Display new class counts\n",
    "print (y_train.value_counts())\n",
    "\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "# Display new class counts\n",
    "print (np.bincount(y_train))\n",
    "\n",
    "#print (Y_train.value_counts() , np.bincount(y_train_res))\n",
    "\n",
    "#5. Model Execution\n",
    "run_all_models(X_train, y_train, X_test, y_test, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
